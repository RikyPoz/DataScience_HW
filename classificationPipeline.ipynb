{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42bfa59c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento dati...\n",
      "Duplicati trovati (Titolo+Articolo): 2954\n",
      "Articoli con lunghezza 0 o < 50 chars: 1524\n",
      "Estrazione feature temporali...\n",
      "Rimossi 2954 duplicati.\n",
      "Pulizia e integrazione Source...\n",
      "Pulizia e integrazione Source...\n",
      "\n",
      "Dati pronti. Train: 61634, Val: 15409\n",
      "\n",
      "--- Inizio Tuning Iperparametri (GridSearch) ---\n",
      "Combinazioni da testare: 6\n",
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "Tuning completato in 171.2 secondi.\n",
      "Migliori parametri: {'clf__C': 0.2, 'preprocessor__tfidf__max_features': None, 'preprocessor__tfidf__ngram_range': (1, 2)}\n",
      "Miglior CV F1 Score: 0.7018\n",
      "\n",
      ">>> REPORT VALIDAZIONE (sul 20% hold-out) <<<\n",
      "Macro F1 Score reale: 0.7081\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.74      0.74      4569\n",
      "           1       0.74      0.82      0.78      2068\n",
      "           2       0.81      0.83      0.82      2175\n",
      "           3       0.64      0.53      0.58      1878\n",
      "           4       0.81      0.95      0.87      1688\n",
      "           5       0.59      0.47      0.52      2445\n",
      "           6       0.53      0.81      0.64       586\n",
      "\n",
      "    accuracy                           0.72     15409\n",
      "   macro avg       0.70      0.73      0.71     15409\n",
      "weighted avg       0.72      0.72      0.71     15409\n",
      "\n",
      "\n",
      "--- Riaddestramento Finale (Full Development Set) ---\n",
      "Applicazione dei migliori parametri all'intero dataset...\n",
      "Modello finale pronto.\n",
      "Predizione su 20000 record di Evaluation...\n",
      "\n",
      "========================================\n",
      "COMPLETATO. File generato: winter_project_2026/sample_submission.csv\n",
      "========================================\n",
      "Verifica header:\n",
      "   Id  Predicted\n",
      "0   0          5\n",
      "1   1          2\n",
      "2   2          5\n",
      "3   3          0\n",
      "4   4          0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import html\n",
    "import time\n",
    "\n",
    "# Importazioni scikit-learn\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# --- 1. CONFIGURAZIONE ---\n",
    "TRAIN_FILE = 'winter_project_2026/development.csv'   \n",
    "EVAL_FILE = 'winter_project_2026/evaluation.csv'     \n",
    "OUTPUT_FILE = 'winter_project_2026/sample_submission.csv'\n",
    "\n",
    "# Definizione della griglia di iperparametri da testare\n",
    "# Il GridSearch proverà tutte le combinazioni per trovare la migliore F1 Macro\n",
    "# PARAM_GRID = {\n",
    "#     'tfidf__max_features': [10000, 20000],      # Vocabolario: 10k o 20k parole\n",
    "#     'tfidf__ngram_range': [(1, 1), (1, 2)],     # Solo singole parole o anche coppie (bigrammi)\n",
    "#     'clf__C': [0.1, 1, 10],                     # Regolarizzazione SVM (Minore = più generico)\n",
    "# }\n",
    "\n",
    "PARAM_GRID = {\n",
    "    'preprocessor__tfidf__max_features': [50000, None],  # Proviamo ad aumentare ancora le parole\n",
    "    'preprocessor__tfidf__ngram_range': [(1, 2)],         \n",
    "    'clf__C': [0.1, 0.2, 0.5],  # Esploriamo intorno a 0.1\n",
    "}\n",
    "\n",
    "# --- 2. CARICAMENTO DATI ---\n",
    "print(f\"Caricamento dati...\")\n",
    "try:\n",
    "    dev_df = pd.read_csv(TRAIN_FILE)\n",
    "    eval_df = pd.read_csv(EVAL_FILE)\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERRORE: Assicurati che '{TRAIN_FILE}' e '{EVAL_FILE}' siano nella stessa cartella.\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. PREPROCESSING ---\n",
    "\n",
    "# 1. Controllo Duplicati\n",
    "duplicates = dev_df.duplicated(subset=['title', 'article']).sum()\n",
    "print(f\"Duplicati trovati (Titolo+Articolo): {duplicates}\")\n",
    "\n",
    "# 2. Controllo Lunghezza Testo\n",
    "dev_df['text_len'] = (dev_df['title'].fillna('') + \" \" + dev_df['article'].fillna('')).apply(len)\n",
    "print(f\"Articoli con lunghezza 0 o < 50 chars: {(dev_df['text_len'] < 50).sum()}\")\n",
    "\n",
    "# 3. Importanza della Source\n",
    "# print(\"\\nEsempio: Top 3 Fonti per la classe 'Technology' (2):\")\n",
    "# tech_sources = dev_df[dev_df['label'] == 2]['source'].value_counts().head(3)\n",
    "# print(tech_sources)\n",
    "# # Vedrai che le fonti sono molto specifiche!\n",
    "# print(\"-\" * 30)\n",
    "\n",
    "def preprocess_text(df, remove_duplicates=False):\n",
    "    \"\"\"\n",
    "    Preprocessing avanzato che include la Fonte e gestisce i duplicati.\n",
    "    \"\"\"\n",
    "    # 1. Rimozione duplicati (Solo per il training, mai per evaluation!)\n",
    "    if remove_duplicates: \n",
    "        initial_len = len(df)\n",
    "        # Rimuoviamo se titolo e articolo sono identici\n",
    "        df = df.drop_duplicates(subset=['title', 'article'], keep='first').copy()\n",
    "        print(f\"Rimossi {initial_len - len(df)} duplicati.\")\n",
    "    else:\n",
    "        # Anche se non rimuoviamo duplicati, facciamo una copia per sicurezza\n",
    "        df = df.copy()\n",
    "\n",
    "    # 2. Feature Engineering: Inseriamo la FONTE nel testo\n",
    "    # La ripetiamo 3 volte per \"urlarla\" al modello (peso maggiore nel TF-IDF)\n",
    "    source_feature = (df['source'].fillna('') + \" \") * 3\n",
    "    \n",
    "    df['text_combined'] = source_feature + df['title'].fillna('') + \" \" + df['article'].fillna('')\n",
    "    \n",
    "    \"\"\" \n",
    "        VECCHIA FUNZIONE: AGGRESSIVA \n",
    "        Rimuove simboli utili (ad esempio, $, %, €), becessari per le classi Business e Technology.    \n",
    "    \"\"\"\n",
    "    def clean(text):\n",
    "        text = str(text).lower()\n",
    "        text = html.unescape(text)\n",
    "        text = re.sub(r'<[^>]+>', ' ', text)\n",
    "        \n",
    "        # --- MODIFICA QUI ---\n",
    "        # Manteniamo lettere, numeri E simboli valuta/percentuale ($, €, %, £)\n",
    "        # La regex precedente era: re.sub(r'[^a-z0-9\\s]', ' ', text)\n",
    "        text = re.sub(r'[^a-z0-9\\s$€%£]', ' ', text) \n",
    "                \n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        return text\n",
    "\n",
    "    print(\"Pulizia e integrazione Source...\")\n",
    "    df['clean_text'] = df['text_combined'].apply(clean)\n",
    "    return df\n",
    "\n",
    "# --- AGGIUNTA FEATURE TEMPORALI ---\n",
    "def extract_time_features(df):\n",
    "    df = df.copy()\n",
    "    # Convertiamo la stringa in oggetto datetime\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "    \n",
    "    # Estraiamo l'ora (0-23) e il giorno della settimana (0=Lun, 6=Dom)\n",
    "    df['hour'] = df['timestamp'].dt.hour.fillna(0)\n",
    "    df['day_of_week'] = df['timestamp'].dt.dayofweek.fillna(0)\n",
    "    return df\n",
    "# \n",
    "# Applichiamo la trasformazione\n",
    "print(\"Estrazione feature temporali...\")\n",
    "dev_df = extract_time_features(dev_df)\n",
    "eval_df = extract_time_features(eval_df)\n",
    "\n",
    "\"\"\" \n",
    "    B. Gestione dei Duplicati (Solo nel Training)\n",
    "    Se nel development.csv  ci sono righe identiche, il modello va in overfitting su quelle frasi. \n",
    "    Dobbiamo rimuovere i duplicati dal set di training, ma MAI dal set di evaluation (perché dobbiamo predire per ogni ID richiesto).\n",
    "\"\"\"\n",
    "dev_df = preprocess_text(dev_df, remove_duplicates=True)\n",
    "eval_df = preprocess_text(eval_df, remove_duplicates=False)\n",
    "\n",
    "# Setup vettori\n",
    "feature_cols = ['clean_text', 'page_rank', 'hour', 'day_of_week']\n",
    "X_dev = dev_df[feature_cols]\n",
    "X_eval = eval_df[feature_cols]\n",
    "\n",
    "y_dev = dev_df['label'] \n",
    "eval_ids = eval_df['Id'] \n",
    "\n",
    "# --- 4. SPLIT TRAIN/VALIDATION ---\n",
    "# Usiamo stratify per mantenere le proporzioni delle classi\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_dev, y_dev, test_size=0.2, random_state=42, stratify=y_dev\n",
    ")\n",
    "\n",
    "print(f\"\\nDati pronti. Train: {len(X_train)}, Val: {len(X_val)}\")\n",
    "\n",
    "# --- 5. PIPELINE E GRID SEARCH ---\n",
    "# Definizione della struttura base\n",
    "# --- AGGIORNAMENTO PIPELINE ---\n",
    "# Usiamo ColumnTransformer per trattare diversamente testo e numeri\n",
    "\"\"\"\n",
    "Stiamo passando da un modello \"solo testo\" a un modello \"ibrido\". \n",
    "ColumnTransformer permette di dire al modello: \"Usa TF-IDF sulla colonna di testo, ma usa la normalizzazione matematica sulla colonna numerica page_rank\", \n",
    "e poi unisci tutto insieme prima di darlo in pasto al classificatore SVM. Senza StandardScaler, il valore del Page Rank (che può essere piccolo o grande) potrebbe essere ignorato o dominare ingiustamente rispetto ai valori TF-IDF.\n",
    "\"\"\"\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # Al testo applichiamo TF-IDF (nota: passiamo la colonna 'clean_text')\n",
    "        ('tfidf', TfidfVectorizer(stop_words='english', min_df=3, sublinear_tf=True), 'clean_text'),\n",
    "        \n",
    "        # Al page_rank applichiamo uno scaler per normalizzarlo (media 0, var 1)\n",
    "        ('num', StandardScaler(), ['page_rank', 'hour', 'day_of_week']) \n",
    "    ]\n",
    ")\n",
    "\n",
    "base_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('clf', LinearSVC(class_weight='balanced', random_state=42, dual='auto'))\n",
    "])\n",
    "\n",
    "print(\"\\n--- Inizio Tuning Iperparametri (GridSearch) ---\")\n",
    "print(f\"Combinazioni da testare: {len(PARAM_GRID['preprocessor__tfidf__max_features']) * len(PARAM_GRID['preprocessor__tfidf__ngram_range']) * len(PARAM_GRID['clf__C'])}\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Configurazione GridSearch\n",
    "# scoring='f1_macro' è fondamentale come da specifiche \n",
    "grid = GridSearchCV(\n",
    "    base_pipeline, \n",
    "    PARAM_GRID, \n",
    "    cv=3,                 # 3-Fold Cross Validation\n",
    "    scoring='f1_macro',   # Metrica obiettivo\n",
    "    n_jobs=-1,            # Usa tutti i processori\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(f\"Tuning completato in {time.time() - start_time:.1f} secondi.\")\n",
    "print(f\"Migliori parametri: {grid.best_params_}\")\n",
    "print(f\"Miglior CV F1 Score: {grid.best_score_:.4f}\")\n",
    "\n",
    "# --- 6. VALIDAZIONE SUL SET DI VALIDATION ---\n",
    "# Usiamo il modello migliore trovato per vedere come va sui dati mai visti (il 20%)\n",
    "best_model_val = grid.best_estimator_\n",
    "y_pred_val = best_model_val.predict(X_val)\n",
    "val_f1 = f1_score(y_val, y_pred_val, average='macro')\n",
    "\n",
    "print(f\"\\n>>> REPORT VALIDAZIONE (sul 20% hold-out) <<<\")\n",
    "print(f\"Macro F1 Score reale: {val_f1:.4f}\")\n",
    "print(classification_report(y_val, y_pred_val))\n",
    "\n",
    "# --- 7. ADDESTRAMENTO FINALE (RETRAINING) ---\n",
    "# Ora che sappiamo quali parametri funzionano meglio, riaddestriamo \n",
    "# un modello nuovo su TUTTO il dataset di development (100% dei dati etichettati)\n",
    "# per avere la massima conoscenza possibile prima della submission.\n",
    "\n",
    "print(\"\\n--- Riaddestramento Finale (Full Development Set) ---\")\n",
    "print(\"Applicazione dei migliori parametri all'intero dataset...\")\n",
    "\n",
    "final_pipeline = Pipeline([\n",
    "    ('preprocessor', ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('tfidf', TfidfVectorizer(\n",
    "                stop_words='english', \n",
    "                min_df=3,\n",
    "                sublinear_tf=True,\n",
    "                max_features=grid.best_params_['preprocessor__tfidf__max_features'],\n",
    "                ngram_range=grid.best_params_['preprocessor__tfidf__ngram_range']\n",
    "            ), 'clean_text'),\n",
    "            ('num', StandardScaler(), ['page_rank', 'hour', 'day_of_week'])\n",
    "        ]\n",
    "    )),\n",
    "    ('clf', LinearSVC(\n",
    "        class_weight='balanced', \n",
    "        random_state=42, \n",
    "        dual='auto',\n",
    "        C=grid.best_params_['clf__C']\n",
    "    ))\n",
    "])\n",
    "\n",
    "final_pipeline.fit(X_dev, y_dev)\n",
    "print(\"Modello finale pronto.\")\n",
    "\n",
    "# --- 8. GENERAZIONE FILE DI SUBMISSION ---\n",
    "print(f\"Predizione su {len(X_eval)} record di Evaluation...\")\n",
    "y_pred_eval = final_pipeline.predict(X_eval)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'Id': eval_ids,\n",
    "    'Predicted': y_pred_eval\n",
    "})\n",
    "\n",
    "# Formattazione corretta CSV: Id, Predicted\n",
    "submission.to_csv(OUTPUT_FILE, index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(f\"COMPLETATO. File generato: {OUTPUT_FILE}\")\n",
    "print(\"=\"*40)\n",
    "print(\"Verifica header:\")\n",
    "print(submission.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
